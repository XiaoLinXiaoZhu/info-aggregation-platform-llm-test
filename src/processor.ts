import { LLMConfig, DataItem, ProcessedItem, ProcessStats, BatchStats } from './config.js';
import { fillTemplate, extractResult } from './template.js';
import { callLLM, delay } from './llm.js';
import { loadDataFile, saveFileResults } from './fileUtils.js';
import * as path from 'path';

// å¤„ç†å•ä¸ªæ•°æ®é¡¹
export async function processDataItem(
  item: DataItem,
  template: string,
  config: LLMConfig,
  itemIndex: number,
  stats: ProcessStats
): Promise<ProcessedItem> {
  const itemStartTime = Date.now();
  console.log(`\n[${itemIndex + 1}] å¼€å§‹å¤„ç†: ${item.title?.substring(0, 50)}...`);
  
  try {
    // å¡«å……æ¨¡æ¿
    const filledPrompt = fillTemplate(template, item);
    const inputChars = filledPrompt.length;
    console.log(`  ğŸ“ è¾“å…¥å­—ç¬¦æ•°: ${inputChars.toLocaleString()}`);
    
    // è°ƒç”¨ LLM
    const { content: response, duration, inputChars: actualInputChars, outputChars } = await callLLM(config, filledPrompt);
    
    // æå–ç»“æœ
    const { result, result_formated } = extractResult(response);
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    stats.totalInputChars += actualInputChars;
    stats.totalOutputChars += outputChars;
    stats.successItems++;
    
    // æ„å»ºå¤„ç†ç»“æœ
    const processedItem: ProcessedItem = {
      original: item,
      reply: {
        context: response,
        result: result,
        result_formated: result_formated,
        time: new Date().toISOString(),
        llmConfig: {
          model: config.model
        }
      }
    };
    
    const itemDuration = Date.now() - itemStartTime;
    console.log(`  âœ… å¤„ç†å®Œæˆ (${itemDuration}ms)`);
    console.log(`  ğŸ“¤ è¾“å‡ºå­—ç¬¦æ•°: ${outputChars.toLocaleString()}`);
    console.log(`  â±ï¸  LLMå“åº”æ—¶é—´: ${duration}ms`);
    console.log(`  ğŸ“Š æ€»è€—æ—¶: ${itemDuration}ms`);
    
    return processedItem;
  } catch (error) {
    stats.failedItems++;
    const itemDuration = Date.now() - itemStartTime;
    console.log(`  âŒ å¤„ç†å¤±è´¥ (${itemDuration}ms): ${error}`);
    throw error;
  }
}

// å¤„ç†å•ä¸ªæ•°æ®æ–‡ä»¶
export async function processDataFile(
  filePath: string,
  template: string,
  config: LLMConfig,
  options: {
    maxItems?: number;
    delayMs?: number;
    saveIndividually?: boolean;
  } = {}
): Promise<{ results: ProcessedItem[]; stats: ProcessStats }> {
  const { maxItems, delayMs = 1000, saveIndividually = true } = options;
  
  console.log(`\nğŸ”„ === å¼€å§‹å¤„ç†æ–‡ä»¶: ${path.basename(filePath)} ===`);
  
  // åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
  const stats: ProcessStats = {
    totalItems: 0,
    successItems: 0,
    failedItems: 0,
    totalInputChars: 0,
    totalOutputChars: 0,
    totalDuration: 0,
    averageResponseTime: 0,
    startTime: Date.now(),
    endTime: 0
  };
  
  // åŠ è½½æ•°æ®
  const dataItems = await loadDataFile(filePath);
  const itemsToProcess = maxItems ? dataItems.slice(0, maxItems) : dataItems;
  
  stats.totalItems = itemsToProcess.length;
  stats.isConcurrent = (config.batch_size || 1) > 1;
  stats.batchStats = [];
  
  console.log(`ğŸ“‹ æ–‡ä»¶åŒ…å« ${dataItems.length.toLocaleString()} ä¸ªæ•°æ®é¡¹ï¼Œå°†å¤„ç† ${itemsToProcess.length.toLocaleString()} ä¸ª`);
  
  const batchSize = config.batch_size || 1;
  if (batchSize > 1) {
    console.log(`âš¡ å¹¶å‘æ¨¡å¼: æ‰¹æ¬¡å¤§å° ${batchSize}`);
  } else {
    console.log(`ğŸ”„ é¡ºåºæ¨¡å¼: é€ä¸ªå¤„ç†`);
  }
  
  const results: ProcessedItem[] = [];
  
  if (batchSize > 1) {
    // å¹¶å‘æ¨¡å¼ï¼šæŒ‰æ‰¹æ¬¡å¤„ç†
    for (let i = 0; i < itemsToProcess.length; i += batchSize) {
      const batch = itemsToProcess.slice(i, i + batchSize);
      const batchId = Math.floor(i / batchSize);
      
      try {
        const { results: batchResults, batchStats } = await processBatchConcurrent(
          batch, 
          template, 
          config, 
          batchId, 
          stats
        );
        
        results.push(...batchResults);
        stats.batchStats!.push(batchStats);
        
        // æ‰¹æ¬¡é—´å»¶è¿Ÿ
        if (i + batchSize < itemsToProcess.length) {
          console.log(`â³ æ‰¹æ¬¡é—´ç­‰å¾… ${delayMs}ms...`);
          await delay(delayMs);
        }
      } catch (error) {
        console.error(`âŒ æ‰¹æ¬¡ ${batchId + 1} å¤„ç†å¤±è´¥:`, error);
      }
    }
  } else {
    // é¡ºåºæ¨¡å¼ï¼šé€ä¸ªå¤„ç†
    for (let i = 0; i < itemsToProcess.length; i++) {
      try {
        const item = itemsToProcess[i];
        const processedItem = await processDataItem(item, template, config, i, stats);
        results.push(processedItem);
        
        // æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        if (i < itemsToProcess.length - 1) {
          console.log(`â³ ç­‰å¾… ${delayMs}ms...`);
          await delay(delayMs);
        }
      } catch (error) {
        console.error(`âŒ å¤„ç†ç¬¬ ${i + 1} ä¸ªé¡¹ç›®æ—¶å‡ºé”™:`, error);
        // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªé¡¹ç›®
      }
    }
  }
  
  // å®Œæˆç»Ÿè®¡
  stats.endTime = Date.now();
  stats.totalDuration = stats.endTime - stats.startTime;
  stats.averageResponseTime = 0; // åœ¨å¹¶å‘æ¨¡å¼ä¸‹è¿™ä¸ªæŒ‡æ ‡æ„ä¹‰ä¸å¤§
  
  // ä¿å­˜å½“å‰æ–‡ä»¶çš„ç»“æœ
  if (saveIndividually && results.length > 0) {
    await saveFileResults(results, path.basename(filePath));
  }
  
  // æ‰“å°æ–‡ä»¶å¤„ç†æ€»ç»“
  console.log(`\nğŸ“Š === æ–‡ä»¶ ${path.basename(filePath)} å¤„ç†å®Œæˆ ===`);
  console.log(`âœ… æˆåŠŸå¤„ç†: ${stats.successItems}/${stats.totalItems} ä¸ªé¡¹ç›®`);
  console.log(`âŒ å¤±è´¥é¡¹ç›®: ${stats.failedItems} ä¸ª`);
  console.log(`ğŸ“ æ€»è¾“å…¥å­—ç¬¦æ•°: ${stats.totalInputChars.toLocaleString()}`);
  console.log(`ğŸ“¤ æ€»è¾“å‡ºå­—ç¬¦æ•°: ${stats.totalOutputChars.toLocaleString()}`);
  console.log(`â±ï¸  æ€»è€—æ—¶: ${(stats.totalDuration / 1000).toFixed(2)}ç§’`);
  console.log(`âš¡ å¹³å‡æ¯é¡¹è€—æ—¶: ${(stats.totalDuration / stats.totalItems / 1000).toFixed(2)}ç§’`);
  
  // å¦‚æœæ˜¯å¹¶å‘æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰¹æ¬¡ç»Ÿè®¡
  if (stats.isConcurrent && stats.batchStats && stats.batchStats.length > 0) {
    console.log(`\nğŸ”„ === æ‰¹æ¬¡å¤„ç†ç»Ÿè®¡ ===`);
    console.log(`ğŸ“¦ æ€»æ‰¹æ¬¡æ•°: ${stats.batchStats.length}`);
    stats.batchStats.forEach((batch, index) => {
      console.log(`  Batch ${batch.batchId}: ${batch.successCount}/${batch.batchSize} æˆåŠŸ, ${(batch.duration / 1000).toFixed(2)}ç§’`);
    });
    
    const avgBatchTime = stats.batchStats.reduce((sum, batch) => sum + batch.duration, 0) / stats.batchStats.length;
    console.log(`ğŸ“ˆ å¹³å‡æ‰¹æ¬¡è€—æ—¶: ${(avgBatchTime / 1000).toFixed(2)}ç§’`);
    
    // è®¡ç®—å¹¶å‘æ•ˆç‡
    const sequentialEstimate = stats.totalItems * (stats.totalDuration / stats.totalItems);
    const speedup = sequentialEstimate / stats.totalDuration;
    console.log(`âš¡ å¹¶å‘åŠ é€Ÿæ¯”: ${speedup.toFixed(2)}x`);
  }
  
  return { results, stats };
}

// æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
export async function processAllFiles(
  filePaths: string[],
  template: string,
  config: LLMConfig,
  options: {
    maxItemsPerFile?: number;
    delayMs?: number;
    saveIndividually?: boolean;
  } = {}
): Promise<{ results: ProcessedItem[]; overallStats: ProcessStats }> {
  const allResults: ProcessedItem[] = [];
  const allStats: ProcessStats[] = [];
  const overallStartTime = Date.now();
  
  console.log(`\nğŸš€ === å¼€å§‹æ‰¹é‡å¤„ç† ${filePaths.length} ä¸ªæ–‡ä»¶ ===`);
  
  for (let fileIndex = 0; fileIndex < filePaths.length; fileIndex++) {
    const filePath = filePaths[fileIndex];
    console.log(`\nğŸ“ [${fileIndex + 1}/${filePaths.length}] å¤„ç†æ–‡ä»¶: ${path.basename(filePath)}`);
    
    try {
      const { results, stats } = await processDataFile(filePath, template, config, {
        maxItems: options.maxItemsPerFile,
        delayMs: options.delayMs,
        saveIndividually: options.saveIndividually
      });
      allResults.push(...results);
      allStats.push(stats);
    } catch (error) {
      console.error(`âŒ å¤„ç†æ–‡ä»¶ ${filePath} å¤±è´¥:`, error);
      // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
    }
  }
  
  // è®¡ç®—æ€»ä½“ç»Ÿè®¡
  const overallStats: ProcessStats = {
    totalItems: allStats.reduce((sum, stat) => sum + stat.totalItems, 0),
    successItems: allStats.reduce((sum, stat) => sum + stat.successItems, 0),
    failedItems: allStats.reduce((sum, stat) => sum + stat.failedItems, 0),
    totalInputChars: allStats.reduce((sum, stat) => sum + stat.totalInputChars, 0),
    totalOutputChars: allStats.reduce((sum, stat) => sum + stat.totalOutputChars, 0),
    totalDuration: Date.now() - overallStartTime,
    averageResponseTime: allStats.length > 0 
      ? allStats.reduce((sum, stat) => sum + stat.averageResponseTime, 0) / allStats.length 
      : 0,
    startTime: overallStartTime,
    endTime: Date.now(),
    isConcurrent: allStats.some(stat => stat.isConcurrent),
    batchStats: allStats.flatMap(stat => stat.batchStats || [])
  };
  
  // æ‰“å°æ€»ä½“ç»Ÿè®¡æŠ¥å‘Š
  console.log(`\nğŸ‰ === æ‰¹é‡å¤„ç†å®Œæˆ ===`);
  console.log(`ğŸ“ å¤„ç†æ–‡ä»¶æ•°: ${filePaths.length}`);
  console.log(`ğŸ“Š æ€»é¡¹ç›®æ•°: ${overallStats.totalItems.toLocaleString()}`);
  console.log(`âœ… æˆåŠŸå¤„ç†: ${overallStats.successItems.toLocaleString()} ä¸ª`);
  console.log(`âŒ å¤±è´¥é¡¹ç›®: ${overallStats.failedItems.toLocaleString()} ä¸ª`);
  console.log(`ğŸ“ˆ æˆåŠŸç‡: ${((overallStats.successItems / overallStats.totalItems) * 100).toFixed(1)}%`);
  console.log(`ğŸ“ æ€»è¾“å…¥å­—ç¬¦æ•°: ${overallStats.totalInputChars.toLocaleString()}`);
  console.log(`ğŸ“¤ æ€»è¾“å‡ºå­—ç¬¦æ•°: ${overallStats.totalOutputChars.toLocaleString()}`);
  console.log(`â±ï¸  æ€»è€—æ—¶: ${(overallStats.totalDuration / 1000 / 60).toFixed(2)} åˆ†é’Ÿ`);
  console.log(`âš¡ å¹³å‡æ¯é¡¹è€—æ—¶: ${(overallStats.totalDuration / overallStats.totalItems / 1000).toFixed(2)} ç§’`);
  
  // å¦‚æœä½¿ç”¨äº†å¹¶å‘æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰¹æ¬¡ç»Ÿè®¡æ±‡æ€»
  if (overallStats.isConcurrent && overallStats.batchStats && overallStats.batchStats.length > 0) {
    console.log(`\nğŸš€ === å¹¶å‘å¤„ç†æ±‡æ€» ===`);
    console.log(`ğŸ“¦ æ€»æ‰¹æ¬¡æ•°: ${overallStats.batchStats.length}`);
    
    const totalBatchTime = overallStats.batchStats.reduce((sum, batch) => sum + batch.duration, 0);
    const avgBatchTime = totalBatchTime / overallStats.batchStats.length;
    console.log(`ï¿½ å¹³å‡æ‰¹æ¬¡è€—æ—¶: ${(avgBatchTime / 1000).toFixed(2)}ç§’`);
    
    // è®¡ç®—ç†è®ºé¡ºåºå¤„ç†æ—¶é—´ vs å®é™…å¹¶å‘å¤„ç†æ—¶é—´
    const avgItemTime = overallStats.totalDuration / overallStats.totalItems;
    const theoreticalSequentialTime = overallStats.totalItems * avgItemTime;
    const speedup = theoreticalSequentialTime / overallStats.totalDuration;
    console.log(`âš¡ å¹¶å‘åŠ é€Ÿæ¯”: ${speedup.toFixed(2)}x`);
    console.log(`ğŸ’¡ æ‰¹æ¬¡å¤§å°: ${overallStats.batchStats[0]?.batchSize || 'N/A'}`);
  }
  
  return { results: allResults, overallStats };
}

// æ‰¹é‡å¹¶å‘å¤„ç†æ•°æ®é¡¹
export async function processBatchConcurrent(
  items: DataItem[],
  template: string,
  config: LLMConfig,
  batchId: number,
  stats: ProcessStats
): Promise<{ results: ProcessedItem[]; batchStats: BatchStats }> {
  const batchStartTime = Date.now();
  console.log(`\nğŸš€ === Batch ${batchId + 1}: å¹¶å‘å¤„ç† ${items.length} ä¸ªé¡¹ç›® ===`);
  
  const batchStats: BatchStats = {
    batchId: batchId + 1,
    batchSize: items.length,
    duration: 0,
    successCount: 0,
    failedCount: 0,
    totalInputChars: 0,
    totalOutputChars: 0,
    startTime: batchStartTime,
    endTime: 0
  };
  
  // å¹¶å‘å¤„ç†æ‰€æœ‰é¡¹ç›®
  const promises = items.map(async (item, index) => {
    try {
      const globalIndex = batchId * config.batch_size! + index;
      const processedItem = await processDataItem(item, template, config, globalIndex, stats);
      batchStats.successCount++;
      return processedItem;
    } catch (error) {
      batchStats.failedCount++;
      console.error(`âŒ Batch ${batchId + 1} é¡¹ç›® ${index + 1} å¤„ç†å¤±è´¥:`, error);
      return null;
    }
  });
  
  const results = (await Promise.all(promises)).filter((item): item is ProcessedItem => item !== null);
  
  batchStats.endTime = Date.now();
  batchStats.duration = batchStats.endTime - batchStats.startTime;
  
  console.log(`âœ… Batch ${batchId + 1} å®Œæˆ: ${batchStats.successCount}/${items.length} æˆåŠŸ, è€—æ—¶ ${(batchStats.duration / 1000).toFixed(2)}ç§’`);
  
  return { results, batchStats };
}
